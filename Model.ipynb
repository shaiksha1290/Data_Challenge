{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Importing Required Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import KFold,cross_val_score,train_test_split\n",
    "from sklearn.linear_model import LinearRegression,Lasso,ElasticNet,LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from __future__ import division\n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_table(r'E:\\AV\\c1_data_science_challenge\\codetest_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_244</th>\n",
       "      <th>f_245</th>\n",
       "      <th>f_246</th>\n",
       "      <th>f_247</th>\n",
       "      <th>f_248</th>\n",
       "      <th>f_249</th>\n",
       "      <th>f_250</th>\n",
       "      <th>f_251</th>\n",
       "      <th>f_252</th>\n",
       "      <th>f_253</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.066056</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>-1.833</td>\n",
       "      <td>-0.736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.115</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>-1.400</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.573</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>-1.244</td>\n",
       "      <td>-0.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.910473</td>\n",
       "      <td>1.179</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>0.811</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-1.243</td>\n",
       "      <td>1.985</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>1.281</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.821</td>\n",
       "      <td>-0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.830711</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.778</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.887</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>1.872</td>\n",
       "      <td>-1.709</td>\n",
       "      <td>0.135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-0.660</td>\n",
       "      <td>1.073</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.570</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>1.435</td>\n",
       "      <td>1.332</td>\n",
       "      <td>-1.147</td>\n",
       "      <td>2.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.180862</td>\n",
       "      <td>0.745</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>1.163</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>0.225</td>\n",
       "      <td>1.223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>1.682</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>0.613</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.462784</td>\n",
       "      <td>1.217</td>\n",
       "      <td>-1.324</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>0.448</td>\n",
       "      <td>-2.873</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>-0.877</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.654</td>\n",
       "      <td>1.230</td>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.754</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target    f_0    f_1    f_2    f_3    f_4    f_5    f_6    f_7    f_8  \\\n",
       "0  3.066056 -0.653  0.255 -0.615 -1.833 -0.736    NaN  1.115 -0.171 -0.351   \n",
       "1 -1.910473  1.179 -0.093 -0.556  0.811 -0.468 -0.005 -0.116 -1.243  1.985   \n",
       "2  7.830711  0.181 -0.778 -0.919  0.113  0.887 -0.762  1.872 -1.709  0.135   \n",
       "3 -2.180862  0.745 -0.245 -1.343  1.163 -0.169 -0.151 -1.100  0.225  1.223   \n",
       "4  5.462784  1.217 -1.324 -0.958  0.448 -2.873 -0.856  0.603  0.763  0.020   \n",
       "\n",
       "   ...    f_244  f_245  f_246  f_247  f_248  f_249  f_250  f_251  f_252  f_253  \n",
       "0  ...   -1.607 -1.400 -0.920 -0.198 -0.945 -0.573  0.170 -0.418 -1.244 -0.503  \n",
       "1  ...    1.282  0.032 -0.061    NaN -0.061 -0.302  1.281 -0.850  0.821 -0.260  \n",
       "2  ...   -0.237 -0.660  1.073 -0.193  0.570 -0.267  1.435  1.332 -1.147  2.580  \n",
       "3  ...    0.709 -0.203 -0.136 -0.571  1.682  0.243 -0.381  0.613  1.033  0.400  \n",
       "4  ...    0.892 -0.433 -0.877  0.289  0.654  1.230  0.457 -0.754 -0.025 -0.931  \n",
       "\n",
       "[5 rows x 255 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data has 0 columsn with more than 5% missing\n",
      "Test data has 0 columsn with more than 5% missing\n"
     ]
    }
   ],
   "source": [
    "# List Percentage of missing values \n",
    "percent_of_missing_train  = data_train.apply(lambda x :  (float(sum(x.isnull()))/len(x))*100 )\n",
    "\n",
    "print \"Train data has \"+str(len(percent_of_missing_train[percent_of_missing_train > 5]))+\" columsn with more than 5% missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target in train has no missing values\n",
    "sum(data_train['target'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Storing Train Categorical column names\n",
    "categorical_col_train = []\n",
    "for x in data_train.columns :\n",
    "    if data_train[x].dtype == 'object' :\n",
    "        categorical_col_train.append(x)\n",
    "\n",
    "\n",
    "train_numerical = data_train.drop(categorical_col_train+['target'],axis=1)\n",
    "train_categorical = data_train[categorical_col_train]\n",
    "train_target = data_train['target']\n",
    "\n",
    "train_panel = pd.concat([train_numerical,train_categorical],axis=1)\n",
    "\n",
    "\n",
    "#Imputing missing values with mean for numerical columns and mode for categorical columns\n",
    "for col in train_panel.columns :\n",
    "    if train_panel[col].dtype == 'object' :\n",
    "        most_occured =  train_panel[col].value_counts().index[0]\n",
    "        train_panel[col].fillna(most_occured,inplace=True)\n",
    "    else:        \n",
    "        train_panel[col].fillna(train_panel[col].mean(),inplace=True)\n",
    "\n",
    "\n",
    "# removing constant columns\n",
    "for colname in train_panel.columns:\n",
    "    if len(np.unique(train_panel[colname].values.astype(\"str\"))) == 1:\n",
    "        del train_panel[colname]\n",
    "        print(\"Column %s has zero variance and is removed from data\" % (colname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating dummy variables\n",
    "train_panel = pd.get_dummies(train_panel, columns=categorical_col_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Multiplying the CV score with -1 to make it positive\n",
    "# Github comments for cross_val_score suggests this is know bug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for Linear Regression : 12.2762917753\n"
     ]
    }
   ],
   "source": [
    "#fitting Linear Model\n",
    "LR = LinearRegression(n_jobs=-1)\n",
    "\n",
    "LR_Cross_val = cross_val_score(LR,train_panel,train_target,cv=10,scoring = 'mean_squared_error').mean()\n",
    "\n",
    "print \"CV Score for Linear Regression : \"+str(-1*LR_Cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplha =0.01    CV: 12.0047100908\n",
      "Aplha =0.06    CV: 11.6373684954\n",
      "Aplha =0.11    CV: 11.8256824701\n",
      "Aplha =0.16    CV: 12.1934675812\n",
      "Aplha =0.21    CV: 12.7057502513\n",
      "Aplha =0.26    CV: 13.101424537\n",
      "Aplha =0.31    CV: 13.5098928473\n",
      "Aplha =0.36    CV: 13.9035465475\n",
      "Aplha =0.41    CV: 14.3558841299\n",
      "Aplha =0.46    CV: 14.8332780499\n"
     ]
    }
   ],
   "source": [
    "#Tunning Alpha for Lasso \n",
    "for i in np.arange(0.01,0.5,0.05) :\n",
    "    las = Lasso(alpha=i)\n",
    "    print \"Aplha =\"+str(i)+\"    CV: \"+str(-1*cross_val_score(las,train_panel,train_target,cv=10,scoring = 'mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for Lasso  : 11.6373684954\n"
     ]
    }
   ],
   "source": [
    "#Fitting Lasso\n",
    "las = Lasso(alpha=0.06)\n",
    "\n",
    "Las_CV = cross_val_score(las,train_panel,train_target,cv=10,scoring = 'mean_squared_error').mean()\n",
    "\n",
    "print \"CV Score for Lasso  : \"+str(-1*Las_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for RandomForest  : 11.9526180324\n"
     ]
    }
   ],
   "source": [
    "#Fitting RandomeForest\n",
    "rf = RandomForestRegressor(n_estimators = 200,n_jobs=-1)\n",
    "\n",
    "RF_cross_val = cross_val_score(rf,train_panel,train_target,cv=10,scoring = 'mean_squared_error').mean()\n",
    "\n",
    "print \"CV Score for RandomForest  : \"+str(-1*RF_cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for ExtraTrees : 11.9028566718\n"
     ]
    }
   ],
   "source": [
    "#Fitting ExtraTrees\n",
    "ET = ExtraTreesRegressor(n_estimators = 200,n_jobs=-1)\n",
    "\n",
    "ET_cross_val = cross_val_score(rf,train_panel,train_target,cv=10,scoring = 'mean_squared_error').mean()\n",
    "\n",
    "print \"CV Score for ExtraTrees : \"+str(-1*ET_cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 columsn have variance ration greater than 0.05\n"
     ]
    }
   ],
   "source": [
    "#Performing PCA\n",
    "pca = PCA(n_components='mle')\n",
    "pca.fit(train_panel)\n",
    "\n",
    "#Explained Varinace ratio\n",
    "NO_cols = len(pca.explained_variance_ratio_[pca.explained_variance_ratio_ > 0.05])\n",
    "print str(NO_cols)+\" columsn have variance ration greater than 0.05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 columns selected\n"
     ]
    }
   ],
   "source": [
    "#Feature selectiong using Lasso\n",
    "Lass = Lasso(alpha = 0.1)\n",
    "Lass = Lass.fit(train_panel,train_target)\n",
    "\n",
    "model_selecting = SelectFromModel(Lass, prefit=True)\n",
    "\n",
    "features_selected = train_panel.columns[model_selecting.get_support()]\n",
    "\n",
    "train_features_subset = model_selecting.transform(train_panel)\n",
    "\n",
    "print str(train_features_subset.shape[1])+\" columns selected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##After Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for Linear Regression : 11.3835117123\n"
     ]
    }
   ],
   "source": [
    "LR_Cross_val = cross_val_score(LR,train_features_subset,train_target,cv=10,scoring = 'mean_squared_error').mean()\n",
    "\n",
    "print \"CV Score for Linear Regression : \"+str(-1*LR_Cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplha =0.01    CV: 11.3877861683\n",
      "Aplha =0.06    CV: 11.5226858288\n",
      "Aplha =0.11    CV: 11.8149578607\n",
      "Aplha =0.16    CV: 12.1934662444\n",
      "Aplha =0.21    CV: 12.7057493736\n",
      "Aplha =0.26    CV: 13.1014249986\n",
      "Aplha =0.31    CV: 13.5098933948\n",
      "Aplha =0.36    CV: 13.9035468551\n",
      "Aplha =0.41    CV: 14.3558851653\n",
      "Aplha =0.46    CV: 14.833278311\n"
     ]
    }
   ],
   "source": [
    "#Tunning Alpha for Lasso \n",
    "for i in np.arange(0.01,0.5,0.05) :\n",
    "    las = Lasso(alpha=i)\n",
    "    print \"Aplha =\"+str(i)+\"    CV: \"+str(-1*cross_val_score(las,train_features_subset,train_target,cv=10,scoring = 'mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for Lasso  : 11.5226858288\n"
     ]
    }
   ],
   "source": [
    "las = Lasso(alpha=0.06)\n",
    "\n",
    "Las_CV = cross_val_score(las,train_features_subset,train_target,cv=10,scoring = 'mean_squared_error').mean()\n",
    "\n",
    "print \"CV Score for Lasso  : \"+str(-1*Las_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for RF  : 9.08456169492\n"
     ]
    }
   ],
   "source": [
    "#RandomeForest\n",
    "rf = RandomForestRegressor(n_estimators = 500,n_jobs=-1,min_samples_split=2,max_features=0.99)\n",
    "\n",
    "rf_cv = cross_val_score(rf,train_features_subset,train_target,cv=10,verbose=0,scoring = 'mean_squared_error').mean() #-9.0946247212837523\n",
    "\n",
    "print \"CV Score for RF  : \"+str(-1*rf_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for ExtraTrees : 9.07589585271\n"
     ]
    }
   ],
   "source": [
    "#Fitting ExtraTrees\n",
    "ET = ExtraTreesRegressor(n_estimators = 500,n_jobs=-1,min_samples_split=2,max_features=0.99)\n",
    "\n",
    "ET_cross_val = cross_val_score(rf,train_features_subset,train_target,cv=10,scoring = 'mean_squared_error').mean()\n",
    "\n",
    "print \"CV Score for ExtraTrees : \"+str(-1*ET_cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'n_estimators': [100, 250, 500],\n",
    "        'learning_rate': [0.05, 0.1, 0.3],\n",
    "        'max_depth': [6, 9],\n",
    "        'subsample': [0.7,0.8,0.9],\n",
    "        'colsample_bytree': [0.7,0.8,0.9],\n",
    "        'gamma':[0.1,0.4,0.6]\n",
    "    }\n",
    "\n",
    "\n",
    "xgb_model = xgboost.XGBRegressor(param)\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs= 3, cv=10,scoring =\"mean_squared_error\")\n",
    "\n",
    "clf.fit(train_features_subset,train_target)\n",
    "\n",
    "score = []\n",
    "par = {'n_estimators':[],'learning_rate':[],\n",
    "       'max_depth':[],'subsample':[],\n",
    "       'colsample_bytree':[],'gamma':[],'scores':[],'min_child_weight':[]\n",
    "      }\n",
    "\n",
    "for i in clf.grid_scores_:\n",
    "    par['scores'].append(i[1])\n",
    "    for k in i[0].keys() :\n",
    "        par[k].append( i[0][k])\n",
    "\n",
    "pd.DataFrame(par).to_csv(r'E:\\AV\\c1_data_science_challenge\\xgboost_tune_parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9000397772\n"
     ]
    }
   ],
   "source": [
    "param_tune = {'max_depth':7, 'learning_rate':0.05 ,'colsample_bytree':0.8,'min_child_weight' : 5 ,'subsample' : 0.8}\n",
    "param_tune['objective'] = 'reg:linear'\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_features_subset,train_target,test_size = 0.4)\n",
    "\n",
    "num_rounds = 500\n",
    "model = xgboost.train(param_tune, xgboost.DMatrix(X_train,y_train), num_rounds)\n",
    "\n",
    "xgb_pred = model.predict(xgboost.DMatrix(X_test),ntree_limit=model.best_iteration)\n",
    "\n",
    "print mean_squared_error(xgb_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data has 0 columsn with more than 5% missing\n"
     ]
    }
   ],
   "source": [
    "#Performing same operation for Test Dataset\n",
    "data_test = pd.read_table(r'E:\\AV\\c1_data_science_challenge\\codetest_test.txt')\n",
    "\n",
    "percent_of_missing_test  = data_test.apply(lambda x :  (float(sum(x.isnull()))/len(x))*100 )\n",
    "print \"Test data has \"+str(len(percent_of_missing_test[percent_of_missing_test > 5]))+\" columsn with more than 5% missing\"\n",
    "\n",
    "#Storing test Categorical column names\n",
    "categorical_col_test = []\n",
    "for x in data_test.columns :\n",
    "    if data_test[x].dtype == 'object' :\n",
    "        categorical_col_test.append(x)\n",
    "\n",
    "\n",
    "test_numerical = data_test.drop(categorical_col_test,axis=1)\n",
    "test_categorical = data_test[categorical_col_test]\n",
    "\n",
    "test_panel = pd.concat([test_numerical,test_categorical],axis=1)\n",
    "\n",
    "\n",
    "#Imputing missing values with mean for numerical columns and mode for categorical columns\n",
    "for col in test_panel.columns :\n",
    "    if test_panel[col].dtype == 'object' :\n",
    "        most_occured =  test_panel[col].value_counts().index[0]\n",
    "        test_panel[col].fillna(most_occured,inplace=True)\n",
    "    else:        \n",
    "        test_panel[col].fillna(test_panel[col].mean(),inplace=True)\n",
    "\n",
    "\n",
    "# removing constant columns\n",
    "for colname in test_panel.columns:\n",
    "    if len(np.unique(test_panel[colname].values.astype(\"str\"))) == 1:\n",
    "        del test_panel[colname]\n",
    "        print(\"Column %s has zero variance and is removed from data\" % (colname))\n",
    "\n",
    "#Creating dummy variables\n",
    "test_panel = pd.get_dummies(test_panel, columns=categorical_col_test)\n",
    "\n",
    "#Subsetting the features\n",
    "test_features_subset = test_panel[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Prediction of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training XGBoost with tuned paramters\n",
    "param_tune = {'max_depth':7, 'learning_rate':0.05 ,'colsample_bytree':0.8,'min_child_weight' : 5 ,'subsample' : 0.8}\n",
    "param_tune['objective'] = 'reg:linear'\n",
    "\n",
    "num_rounds = 1000\n",
    "model = xgboost.train(param_tune, xgboost.DMatrix(train_features_subset,train_target), num_rounds)\n",
    "\n",
    "xgb_pred = model.predict(xgboost.DMatrix(test_features_subset),ntree_limit=model.best_iteration)\n",
    "\n",
    "pd.DataFrame(xgb_pred).to_csv(r'E:\\AV\\c1_data_science_challenge\\codetest_prediction.txt',header=False,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
